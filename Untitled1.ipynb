{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f7daec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import GeoDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddae738e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset = datasets.load_diabetes(as_frame=True)\n",
    "\n",
    "X = dataset.data\n",
    "y = dataset.target\n",
    "\n",
    "y = y.to_frame()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c36dfe55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from GeoDS.supervised import pipelineator\n",
    "from GeoDS.supervised import tuning\n",
    "X, y = load_breast_cancer(return_X_y=True, as_frame=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "n_classes = len(np.unique(y))\n",
    "cat_indices = X_train.columns.get_indexer(X_train.select_dtypes('object').columns)\n",
    "#dp = pipelineator.DefaultSupervisedPipeline(categorical_features_indices=cat_indices, objective='binary', lgbm_num_classes=n_classes)\n",
    "dp = pipelineator.DefaultSupervisedPipeline()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d855425",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-20 22:31:02,603]\u001b[0m A new study created in memory with name: test\u001b[0m\n",
      "\u001b[32m[I 2022-09-20 22:31:05,236]\u001b[0m Trial 0 finished with value: 0.9619485208278313 and parameters: {'clf__bosting_type': 'dart', 'clf__num_leaves': 124, 'clf__min_data': 73, 'clf__max_depth': 5, 'clf__reg_alpha': 0.05808361216819946, 'clf__reg_lambda': 0.8661761457749352, 'clf__learning_rate': 0.19956529392808392, 'drop_rate': 0.004619347374377372, 'skip_drop': 1.4610865886287176e-08}. Best is trial 0 with value: 0.9619485208278313.\u001b[0m\n",
      "\u001b[32m[I 2022-09-20 22:31:05,430]\u001b[0m Trial 1 finished with value: 0.9619485208278313 and parameters: {'clf__bosting_type': 'gbdt', 'clf__num_leaves': 44, 'clf__min_data': 77, 'clf__max_depth': 6, 'clf__reg_alpha': 0.5247564316322378, 'clf__reg_lambda': 0.43194501864211576, 'clf__learning_rate': 0.09776854331372624}. Best is trial 0 with value: 0.9619485208278313.\u001b[0m\n",
      "\u001b[32m[I 2022-09-20 22:31:05,620]\u001b[0m Trial 2 finished with value: 0.9619485208278313 and parameters: {'clf__bosting_type': 'gbdt', 'clf__num_leaves': 79, 'clf__min_data': 118, 'clf__max_depth': 11, 'clf__reg_alpha': 0.19967378215835974, 'clf__reg_lambda': 0.5142344384136116, 'clf__learning_rate': 0.19560708142748476}. Best is trial 0 with value: 0.9619485208278313.\u001b[0m\n",
      "\u001b[32m[I 2022-09-20 22:31:05,805]\u001b[0m Trial 3 finished with value: 0.9619485208278313 and parameters: {'clf__bosting_type': 'dart', 'clf__num_leaves': 22, 'clf__min_data': 193, 'clf__max_depth': 12, 'clf__reg_alpha': 0.8083973481164611, 'clf__reg_lambda': 0.3046137691733707, 'clf__learning_rate': 0.06260977143530197, 'drop_rate': 0.0029775853025212607, 'skip_drop': 3.320625892007924e-05}. Best is trial 0 with value: 0.9619485208278313.\u001b[0m\n",
      "\u001b[32m[I 2022-09-20 22:31:05,995]\u001b[0m Trial 4 finished with value: 0.9619485208278313 and parameters: {'clf__bosting_type': 'dart', 'clf__num_leaves': 183, 'clf__min_data': 89, 'clf__max_depth': 9, 'clf__reg_alpha': 0.31171107608941095, 'clf__reg_lambda': 0.5200680211778108, 'clf__learning_rate': 0.1760679402733934, 'drop_rate': 3.0118659882617117e-07, 'skip_drop': 0.5710537951126793}. Best is trial 0 with value: 0.9619485208278313.\u001b[0m\n",
      "\u001b[32m[I 2022-09-20 22:31:06,010]\u001b[0m A new study created in memory with name: test\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained models saved in ./models/ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-20 22:31:06,620]\u001b[0m Trial 0 finished with value: 0.9434793996425593 and parameters: {'n_estimators': 250, 'max_features': 'auto', 'max_depth': 32, 'min_samples_split': 3, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 0 with value: 0.9434793996425593.\u001b[0m\n",
      "\u001b[32m[I 2022-09-20 22:31:07,236]\u001b[0m Trial 1 finished with value: 0.9434793996425593 and parameters: {'n_estimators': 341, 'max_features': 'auto', 'max_depth': 49, 'min_samples_split': 9, 'min_samples_leaf': 3, 'bootstrap': False}. Best is trial 0 with value: 0.9434793996425593.\u001b[0m\n",
      "\u001b[32m[I 2022-09-20 22:31:07,846]\u001b[0m Trial 2 finished with value: 0.9434793996425593 and parameters: {'n_estimators': 222, 'max_features': 'auto', 'max_depth': 18, 'min_samples_split': 7, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 0 with value: 0.9434793996425593.\u001b[0m\n",
      "\u001b[32m[I 2022-09-20 22:31:08,456]\u001b[0m Trial 3 finished with value: 0.9434793996425593 and parameters: {'n_estimators': 282, 'max_features': 'auto', 'max_depth': 28, 'min_samples_split': 7, 'min_samples_leaf': 1, 'bootstrap': True}. Best is trial 0 with value: 0.9434793996425593.\u001b[0m\n",
      "\u001b[32m[I 2022-09-20 22:31:09,073]\u001b[0m Trial 4 finished with value: 0.9434793996425593 and parameters: {'n_estimators': 126, 'max_features': 'sqrt', 'max_depth': 42, 'min_samples_split': 4, 'min_samples_leaf': 1, 'bootstrap': True}. Best is trial 0 with value: 0.9434793996425593.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained models saved in ./models/ \n"
     ]
    }
   ],
   "source": [
    "pipes = [dp.lgbm_pipeline, dp.random_forest_pipeline]\n",
    "for p in pipes:\n",
    "    lambda_objective = lambda trial: tuning.objective(trial, pipeline=p, X_train=X_train, y_train=y_train, cross_validator=5, groups=None, scoring_metric='f1_macro')\n",
    "    my_pipe, my_study = tuning.tune(n_trials=5, objective_function=lambda_objective\n",
    "                                    , output_folder='./', study_name='test', random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acaf10ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994cbba6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8fbbc455",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_objective = lambda trial, p: tuning.objective(trial, \n",
    "                                                  pipeline=p,\n",
    "                                                  X_train=X_train, \n",
    "                                                  y_train=y_train, \n",
    "                                                  cross_validator=5,\n",
    "                                                  groups=None,\n",
    "                                                  scoring_metric='f1_macro')\n",
    "\n",
    "my_pipe, my_study = tuning.tune(n_trials=3, \n",
    "                                objective_function=lambda_objective(), \n",
    "                                output_folder='./', \n",
    "                                study_name='test',\n",
    "                                random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "790ca16d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-20 21:57:51,787]\u001b[0m A new study created in memory with name: test\u001b[0m\n",
      "\u001b[33m[W 2022-09-20 21:57:51,789]\u001b[0m Trial 0 failed because of the following error: TypeError(\"<lambda>() missing 1 required positional argument: 'p'\")\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/geods37/lib/python3.7/site-packages/optuna/study/_optimize.py\", line 213, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "TypeError: <lambda>() missing 1 required positional argument: 'p'\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "<lambda>() missing 1 required positional argument: 'p'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13/2284143128.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmy_pipe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmy_study\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtune\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobjective_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlambda_objective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_folder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/geods37/lib/python3.7/site-packages/GeoDS-1.1.0-py3.7.egg/GeoDS/supervised/tuning.py\u001b[0m in \u001b[0;36mtune\u001b[0;34m(n_trials, objective_function, output_folder, study_name, random_state)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0mobjective_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m         \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_trials\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m         callbacks=[callback])\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0mpipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_attrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"best_pipeline\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/geods37/lib/python3.7/site-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgc_after_trial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m             \u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m         )\n\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/geods37/lib/python3.7/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0mreseed_sampler_rng\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0mtime_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                 \u001b[0mprogress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             )\n\u001b[1;32m     78\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/geods37/lib/python3.7/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/geods37/lib/python3.7/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTrialState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFAIL\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfunc_err\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/geods37/lib/python3.7/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: <lambda>() missing 1 required positional argument: 'p'"
     ]
    }
   ],
   "source": [
    "my_pipe, my_study = tuning.tune(n_trials=3, \n",
    "                                objective_function=lambda_objective(), \n",
    "                                output_folder='./', \n",
    "                                study_name='test',\n",
    "                                random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3971670a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a907a8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0f41d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-20 18:53:32,161]\u001b[0m A new study created in memory with name: test\u001b[0m\n",
      "\u001b[32m[I 2022-09-20 18:53:32,355]\u001b[0m Trial 0 finished with value: 0.9619485208278313 and parameters: {'clf__bosting_type': 'dart', 'clf__num_leaves': 124, 'clf__min_data': 73, 'clf__max_depth': 5, 'clf__reg_alpha': 0.05808361216819946, 'clf__reg_lambda': 0.8661761457749352, 'clf__learning_rate': 0.19956529392808392, 'drop_rate': 0.004619347374377372, 'skip_drop': 1.4610865886287176e-08}. Best is trial 0 with value: 0.9619485208278313.\u001b[0m\n",
      "\u001b[32m[I 2022-09-20 18:53:32,546]\u001b[0m Trial 1 finished with value: 0.9596302411947686 and parameters: {'clf__bosting_type': 'gbdt', 'clf__num_leaves': 44, 'clf__min_data': 77, 'clf__max_depth': 6, 'clf__reg_alpha': 0.5247564316322378, 'clf__reg_lambda': 0.43194501864211576, 'clf__learning_rate': 0.09776854331372624}. Best is trial 0 with value: 0.9619485208278313.\u001b[0m\n",
      "\u001b[32m[I 2022-09-20 18:53:32,703]\u001b[0m Trial 2 finished with value: 0.960066504395955 and parameters: {'clf__bosting_type': 'gbdt', 'clf__num_leaves': 79, 'clf__min_data': 118, 'clf__max_depth': 11, 'clf__reg_alpha': 0.19967378215835974, 'clf__reg_lambda': 0.5142344384136116, 'clf__learning_rate': 0.19560708142748476}. Best is trial 0 with value: 0.9619485208278313.\u001b[0m\n",
      "\u001b[32m[I 2022-09-20 18:53:32,850]\u001b[0m Trial 3 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-20 18:53:33,025]\u001b[0m Trial 4 finished with value: 0.9645288663576721 and parameters: {'clf__bosting_type': 'dart', 'clf__num_leaves': 183, 'clf__min_data': 89, 'clf__max_depth': 9, 'clf__reg_alpha': 0.31171107608941095, 'clf__reg_lambda': 0.5200680211778108, 'clf__learning_rate': 0.1760679402733934, 'drop_rate': 3.0118659882617117e-07, 'skip_drop': 0.5710537951126793}. Best is trial 4 with value: 0.9645288663576721.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained models saved in ./models/ \n"
     ]
    }
   ],
   "source": [
    "lambda_objective = lambda trial: tuning.objective(trial, pipeline=dp.lgbm_pipeline, X_train=X_train, y_train=y_train, cross_validator=5, groups=None, scoring_metric='f1_macro')\n",
    "my_pipe, my_study = tuning.tune(n_trials=5, objective_function=lambda_objective, output_folder='./', study_name='test', random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "c9220a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_objective = lambda trial: tuning.objective(trial, pipeline=dp.lgbm_pipeline,\n",
    "                                                  X_train=X_train, y_train=y_train, \n",
    "                                                  cross_validator=5, groups=None, \n",
    "                                                  scoring_metric='f1_macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "4faced6c",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'suggest_categorical'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13/62777772.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlambda_objective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_13/30874997.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m      2\u001b[0m                                                   \u001b[0mX_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                                   \u001b[0mcross_validator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                                                   scoring_metric='f1_macro')\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/geods37/lib/python3.7/site-packages/GeoDS-1.1.0-py3.7.egg/GeoDS/supervised/tuning.py\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial, pipeline, X_train, y_train, cross_validator, groups, scoring_metric, tune_on)\u001b[0m\n\u001b[1;32m    201\u001b[0m     \"\"\"\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m     \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSuggestor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clf'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0mpipeline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clf'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/geods37/lib/python3.7/site-packages/GeoDS-1.1.0-py3.7.egg/GeoDS/supervised/tuning.py\u001b[0m in \u001b[0;36mget_params\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madaboost_params_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mLGBMClassifier\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m             \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlgbm_params_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexisting_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/geods37/lib/python3.7/site-packages/GeoDS-1.1.0-py3.7.egg/GeoDS/supervised/tuning.py\u001b[0m in \u001b[0;36mlightgbm_params\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlightgbm_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     params = {\"boosting_type\": trial.suggest_categorical(\"clf__bosting_type\", ['gbdt', 'dart', 'goss']),\n\u001b[0m\u001b[1;32m     44\u001b[0m               \u001b[0;34m\"num_leaves\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'clf__num_leaves'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m               \u001b[0;34m\"min_data\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'clf__min_data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'suggest_categorical'"
     ]
    }
   ],
   "source": [
    "lambda_objective(trial=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7024435b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-20 18:54:10,940]\u001b[0m A new study created in memory with name: test\u001b[0m\n",
      "\u001b[32m[I 2022-09-20 18:54:11,136]\u001b[0m Trial 0 finished with value: 0.9619485208278313 and parameters: {'clf__bosting_type': 'dart', 'clf__num_leaves': 124, 'clf__min_data': 73, 'clf__max_depth': 5, 'clf__reg_alpha': 0.05808361216819946, 'clf__reg_lambda': 0.8661761457749352, 'clf__learning_rate': 0.19956529392808392, 'drop_rate': 0.004619347374377372, 'skip_drop': 1.4610865886287176e-08}. Best is trial 0 with value: 0.9619485208278313.\u001b[0m\n",
      "\u001b[32m[I 2022-09-20 18:54:11,325]\u001b[0m Trial 1 finished with value: 0.9596302411947686 and parameters: {'clf__bosting_type': 'gbdt', 'clf__num_leaves': 44, 'clf__min_data': 77, 'clf__max_depth': 6, 'clf__reg_alpha': 0.5247564316322378, 'clf__reg_lambda': 0.43194501864211576, 'clf__learning_rate': 0.09776854331372624}. Best is trial 0 with value: 0.9619485208278313.\u001b[0m\n",
      "\u001b[32m[I 2022-09-20 18:54:11,478]\u001b[0m Trial 2 finished with value: 0.960066504395955 and parameters: {'clf__bosting_type': 'gbdt', 'clf__num_leaves': 79, 'clf__min_data': 118, 'clf__max_depth': 11, 'clf__reg_alpha': 0.19967378215835974, 'clf__reg_lambda': 0.5142344384136116, 'clf__learning_rate': 0.19560708142748476}. Best is trial 0 with value: 0.9619485208278313.\u001b[0m\n",
      "\u001b[32m[I 2022-09-20 18:54:11,618]\u001b[0m Trial 3 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-20 18:54:11,793]\u001b[0m Trial 4 finished with value: 0.9645288663576721 and parameters: {'clf__bosting_type': 'dart', 'clf__num_leaves': 183, 'clf__min_data': 89, 'clf__max_depth': 9, 'clf__reg_alpha': 0.31171107608941095, 'clf__reg_lambda': 0.5200680211778108, 'clf__learning_rate': 0.1760679402733934, 'drop_rate': 3.0118659882617117e-07, 'skip_drop': 0.5710537951126793}. Best is trial 4 with value: 0.9645288663576721.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained models saved in ./models/ \n"
     ]
    }
   ],
   "source": [
    "lambda_objective2 = lambda trial2: tuning.objective(trial2, pipeline=dp.lgbm_pipeline, X_train=X_train, y_train=y_train, cross_validator=5, groups=None, scoring_metric='f1_macro')\n",
    "my_pipe, my_study = tuning.tune(n_trials=5, objective_function=lambda_objective2, output_folder='./', study_name='test', random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d88c61c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-20 19:01:25,000]\u001b[0m A new study created in memory with name: test\u001b[0m\n",
      "\u001b[32m[I 2022-09-20 19:01:27,717]\u001b[0m Trial 0 finished with value: 0.9619485208278313 and parameters: {'clf__bosting_type': 'dart', 'clf__num_leaves': 124, 'clf__min_data': 73, 'clf__max_depth': 5, 'clf__reg_alpha': 0.05808361216819946, 'clf__reg_lambda': 0.8661761457749352, 'clf__learning_rate': 0.19956529392808392, 'drop_rate': 0.004619347374377372, 'skip_drop': 1.4610865886287176e-08}. Best is trial 0 with value: 0.9619485208278313.\u001b[0m\n",
      "\u001b[32m[I 2022-09-20 19:01:27,910]\u001b[0m Trial 1 finished with value: 0.9619485208278313 and parameters: {'clf__bosting_type': 'gbdt', 'clf__num_leaves': 44, 'clf__min_data': 77, 'clf__max_depth': 6, 'clf__reg_alpha': 0.5247564316322378, 'clf__reg_lambda': 0.43194501864211576, 'clf__learning_rate': 0.09776854331372624}. Best is trial 0 with value: 0.9619485208278313.\u001b[0m\n",
      "\u001b[32m[I 2022-09-20 19:01:28,103]\u001b[0m Trial 2 finished with value: 0.9619485208278313 and parameters: {'clf__bosting_type': 'gbdt', 'clf__num_leaves': 79, 'clf__min_data': 118, 'clf__max_depth': 11, 'clf__reg_alpha': 0.19967378215835974, 'clf__reg_lambda': 0.5142344384136116, 'clf__learning_rate': 0.19560708142748476}. Best is trial 0 with value: 0.9619485208278313.\u001b[0m\n",
      "\u001b[32m[I 2022-09-20 19:01:28,302]\u001b[0m Trial 3 finished with value: 0.9619485208278313 and parameters: {'clf__bosting_type': 'dart', 'clf__num_leaves': 22, 'clf__min_data': 193, 'clf__max_depth': 12, 'clf__reg_alpha': 0.8083973481164611, 'clf__reg_lambda': 0.3046137691733707, 'clf__learning_rate': 0.06260977143530197, 'drop_rate': 0.0029775853025212607, 'skip_drop': 3.320625892007924e-05}. Best is trial 0 with value: 0.9619485208278313.\u001b[0m\n",
      "\u001b[32m[I 2022-09-20 19:01:28,496]\u001b[0m Trial 4 finished with value: 0.9619485208278313 and parameters: {'clf__bosting_type': 'dart', 'clf__num_leaves': 183, 'clf__min_data': 89, 'clf__max_depth': 9, 'clf__reg_alpha': 0.31171107608941095, 'clf__reg_lambda': 0.5200680211778108, 'clf__learning_rate': 0.1760679402733934, 'drop_rate': 3.0118659882617117e-07, 'skip_drop': 0.5710537951126793}. Best is trial 0 with value: 0.9619485208278313.\u001b[0m\n",
      "\u001b[32m[I 2022-09-20 19:01:28,510]\u001b[0m A new study created in memory with name: test\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained models saved in ./models/ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-20 19:02:05,655]\u001b[0m Trial 0 finished with value: 0.9502064972526412 and parameters: {'max_depth': 5, 'learning_rate': 0.8627358286640178, 'n_estimators': 197, 'min_child_weight': 12, 'scale_pos_weight': 16, 'subsample': 0.15599452033620265, 'colsample_bytree': 0.05808361216819946}. Best is trial 0 with value: 0.9502064972526412.\u001b[0m\n",
      "\u001b[32m[I 2022-09-20 19:02:40,554]\u001b[0m Trial 1 finished with value: 0.9502064972526412 and parameters: {'max_depth': 11, 'learning_rate': 0.30271829277346235, 'n_estimators': 192, 'min_child_weight': 1, 'scale_pos_weight': 97, 'subsample': 0.8324426408004217, 'colsample_bytree': 0.21233911067827616}. Best is trial 0 with value: 0.9502064972526412.\u001b[0m\n",
      "\u001b[32m[I 2022-09-20 19:03:06,481]\u001b[0m Trial 2 finished with value: 0.9502064972526412 and parameters: {'max_depth': 3, 'learning_rate': 0.0866133373527313, 'n_estimators': 111, 'min_child_weight': 11, 'scale_pos_weight': 44, 'subsample': 0.2912291401980419, 'colsample_bytree': 0.6118528947223795}. Best is trial 0 with value: 0.9502064972526412.\u001b[0m\n",
      "\u001b[32m[I 2022-09-20 19:03:34,878]\u001b[0m Trial 3 finished with value: 0.9502064972526412 and parameters: {'max_depth': 2, 'learning_rate': 0.11996621453406359, 'n_estimators': 123, 'min_child_weight': 10, 'scale_pos_weight': 79, 'subsample': 0.19967378215835974, 'colsample_bytree': 0.5142344384136116}. Best is trial 0 with value: 0.9502064972526412.\u001b[0m\n",
      "\u001b[32m[I 2022-09-20 19:04:15,630]\u001b[0m Trial 4 finished with value: 0.9502064972526412 and parameters: {'max_depth': 8, 'learning_rate': 0.05746499650110707, 'n_estimators': 172, 'min_child_weight': 4, 'scale_pos_weight': 7, 'subsample': 0.9488855372533332, 'colsample_bytree': 0.9656320330745594}. Best is trial 0 with value: 0.9502064972526412.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained models saved in ./models/ \n"
     ]
    }
   ],
   "source": [
    "pipes = [dp.lgbm_pipeline, dp.xgboost_pipeline]\n",
    "for p in pipes:\n",
    "    lambda_objective = lambda trial: tuning.objective(trial, pipeline=p, X_train=X_train, y_train=y_train, cross_validator=5, groups=None, scoring_metric='f1_macro')\n",
    "    my_pipe, my_study = tuning.tune(n_trials=5, objective_function=lambda_objective\n",
    "                                    , output_folder='./', study_name='test', random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb62b805",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-20 19:12:28,571]\u001b[0m A new study created in memory with name: test\u001b[0m\n",
      "\u001b[32m[I 2022-09-20 19:13:08,012]\u001b[0m Trial 0 finished with value: 0.9619485208278313 and parameters: {'clf__bosting_type': 'dart', 'clf__num_leaves': 124, 'clf__min_data': 73, 'clf__max_depth': 5, 'clf__reg_alpha': 0.05808361216819946, 'clf__reg_lambda': 0.8661761457749352, 'clf__learning_rate': 0.19956529392808392, 'drop_rate': 0.004619347374377372, 'skip_drop': 1.4610865886287176e-08}. Best is trial 0 with value: 0.9619485208278313.\u001b[0m\n",
      "\u001b[32m[I 2022-09-20 19:13:08,023]\u001b[0m A new study created in memory with name: test\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained models saved in ./models/ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-20 19:13:08,650]\u001b[0m Trial 0 finished with value: 0.9434793996425593 and parameters: {'n_estimators': 250, 'max_features': 'auto', 'max_depth': 32, 'min_samples_split': 3, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 0 with value: 0.9434793996425593.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained models saved in ./models/ \n"
     ]
    }
   ],
   "source": [
    "pipes = [dp.lgbm_pipeline, dp.random_forest_pipeline]\n",
    "for p in pipes:\n",
    "    lambda_objective = lambda trial, p=p: tuning.objective(trial, pipeline=p, X_train=X_train, y_train=y_train, cross_validator=5, groups=None, scoring_metric='f1_macro')\n",
    "    my_pipe, my_study = tuning.tune(n_trials=1, objective_function=lambda_objective\n",
    "                                    ,output_folder='./', study_name='test', random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "99a1bb45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-20 19:13:27,784]\u001b[0m A new study created in memory with name: test\u001b[0m\n",
      "\u001b[32m[I 2022-09-20 19:14:09,246]\u001b[0m Trial 0 finished with value: 0.9619485208278313 and parameters: {'clf__bosting_type': 'dart', 'clf__num_leaves': 124, 'clf__min_data': 73, 'clf__max_depth': 5, 'clf__reg_alpha': 0.05808361216819946, 'clf__reg_lambda': 0.8661761457749352, 'clf__learning_rate': 0.19956529392808392, 'drop_rate': 0.004619347374377372, 'skip_drop': 1.4610865886287176e-08}. Best is trial 0 with value: 0.9619485208278313.\u001b[0m\n",
      "\u001b[32m[I 2022-09-20 19:14:09,258]\u001b[0m A new study created in memory with name: test\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained models saved in ./models/ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-20 19:14:09,899]\u001b[0m Trial 0 finished with value: 0.9434793996425593 and parameters: {'n_estimators': 250, 'max_features': 'auto', 'max_depth': 32, 'min_samples_split': 3, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 0 with value: 0.9434793996425593.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained models saved in ./models/ \n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[19:01:30] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:02:05] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:02:41] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:03:06] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:03:36] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[19:01:29] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:02:06] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:02:41] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:03:07] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:03:36] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/geods37/lib/python3.7/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/root/miniconda3/envs/geods37/lib/python3.7/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/root/miniconda3/envs/geods37/lib/python3.7/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/root/miniconda3/envs/geods37/lib/python3.7/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/root/miniconda3/envs/geods37/lib/python3.7/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/root/miniconda3/envs/geods37/lib/python3.7/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/root/miniconda3/envs/geods37/lib/python3.7/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/root/miniconda3/envs/geods37/lib/python3.7/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/root/miniconda3/envs/geods37/lib/python3.7/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/root/miniconda3/envs/geods37/lib/python3.7/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/root/miniconda3/envs/geods37/lib/python3.7/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/root/miniconda3/envs/geods37/lib/python3.7/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/root/miniconda3/envs/geods37/lib/python3.7/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/root/miniconda3/envs/geods37/lib/python3.7/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/root/miniconda3/envs/geods37/lib/python3.7/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/root/miniconda3/envs/geods37/lib/python3.7/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/root/miniconda3/envs/geods37/lib/python3.7/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/root/miniconda3/envs/geods37/lib/python3.7/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/root/miniconda3/envs/geods37/lib/python3.7/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/root/miniconda3/envs/geods37/lib/python3.7/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/root/miniconda3/envs/geods37/lib/python3.7/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/root/miniconda3/envs/geods37/lib/python3.7/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/root/miniconda3/envs/geods37/lib/python3.7/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/root/miniconda3/envs/geods37/lib/python3.7/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/root/miniconda3/envs/geods37/lib/python3.7/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[19:01:30] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:01:54] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:02:06] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:02:36] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:02:40] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:02:49] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:03:06] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:03:36] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[19:01:30] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:02:06] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:02:41] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:03:07] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:03:16] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:03:34] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:04:06] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n"
     ]
    }
   ],
   "source": [
    "pipes = [dp.lgbm_pipeline, dp.random_forest_pipeline]\n",
    "for p in pipes:\n",
    "    lambda_objective = lambda trial: tuning.objective(trial, pipeline=p, X_train=X_train, y_train=y_train, cross_validator=5, groups=None, scoring_metric='f1_macro')\n",
    "    my_pipe, my_study = tuning.tune(n_trials=1, objective_function=lambda_objective\n",
    "                                    ,output_folder='./', study_name='test', random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "de018424",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-20 19:34:02,578]\u001b[0m A new study created in memory with name: test\u001b[0m\n",
      "\u001b[32m[I 2022-09-20 19:34:05,179]\u001b[0m Trial 0 finished with value: 0.9619485208278313 and parameters: {'clf__bosting_type': 'dart', 'clf__num_leaves': 124, 'clf__min_data': 73, 'clf__max_depth': 5, 'clf__reg_alpha': 0.05808361216819946, 'clf__reg_lambda': 0.8661761457749352, 'clf__learning_rate': 0.19956529392808392, 'drop_rate': 0.004619347374377372, 'skip_drop': 1.4610865886287176e-08}. Best is trial 0 with value: 0.9619485208278313.\u001b[0m\n",
      "\u001b[32m[I 2022-09-20 19:34:05,369]\u001b[0m Trial 1 finished with value: 0.9619485208278313 and parameters: {'clf__bosting_type': 'gbdt', 'clf__num_leaves': 44, 'clf__min_data': 77, 'clf__max_depth': 6, 'clf__reg_alpha': 0.5247564316322378, 'clf__reg_lambda': 0.43194501864211576, 'clf__learning_rate': 0.09776854331372624}. Best is trial 0 with value: 0.9619485208278313.\u001b[0m\n",
      "\u001b[32m[I 2022-09-20 19:34:05,381]\u001b[0m A new study created in memory with name: test\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained models saved in ./models/ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-20 19:34:42,522]\u001b[0m Trial 0 finished with value: 0.9502064972526412 and parameters: {'max_depth': 5, 'learning_rate': 0.8627358286640178, 'n_estimators': 197, 'min_child_weight': 12, 'scale_pos_weight': 16, 'subsample': 0.15599452033620265, 'colsample_bytree': 0.05808361216819946}. Best is trial 0 with value: 0.9502064972526412.\u001b[0m\n",
      "\u001b[32m[I 2022-09-20 19:35:20,797]\u001b[0m Trial 1 finished with value: 0.9502064972526412 and parameters: {'max_depth': 11, 'learning_rate': 0.30271829277346235, 'n_estimators': 192, 'min_child_weight': 1, 'scale_pos_weight': 97, 'subsample': 0.8324426408004217, 'colsample_bytree': 0.21233911067827616}. Best is trial 0 with value: 0.9502064972526412.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained models saved in ./models/ \n"
     ]
    }
   ],
   "source": [
    "pipes = [dp.lgbm_pipeline, dp.xgboost_pipeline]\n",
    "\n",
    "for i, pipe in enumerate(pipes):\n",
    "    lambda_objective = lambda trial, i=i: tuning.objective(trial, pipeline=pipes[i], X_train=X_train, y_train=y_train, cross_validator=5, groups=None, scoring_metric='f1_macro')\n",
    "    my_pipe, my_study = tuning.tune(n_trials=2, objective_function=lambda_objective\n",
    "                                    ,output_folder='./', study_name='test', random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16181e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipes = [dp.lgbm_pipeline, dp.random_forest_pipeline]\n",
    "\n",
    "pipe_list = []\n",
    "for i, pipe in enumerate(pipes):\n",
    "    pipe_list.append(pipes[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aeceafd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Pipeline(steps=[('pre',\n",
       "                  ColumnTransformer(transformers=[('numerical_transfo',\n",
       "                                                   Pipeline(steps=[('scaler',\n",
       "                                                                    StandardScaler())]),\n",
       "                                                   <sklearn.compose._column_transformer.make_column_selector object at 0x7f3b7ef58990>),\n",
       "                                                  ('categorical_transfo',\n",
       "                                                   Pipeline(steps=[('encoder',\n",
       "                                                                    OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                   <sklearn.compose._column_transformer.make_column_selector object at 0x7f3b7ef58e50>)])),\n",
       "                 ('imb', SMOTEENN(random_state=42)),\n",
       "                 ('clf', LGBMClassifier(objective='binary', random_state=42))]),\n",
       " Pipeline(steps=[('pre',\n",
       "                  ColumnTransformer(transformers=[('numerical_transfo',\n",
       "                                                   Pipeline(steps=[('scaler',\n",
       "                                                                    StandardScaler())]),\n",
       "                                                   <sklearn.compose._column_transformer.make_column_selector object at 0x7f3b7ef58990>),\n",
       "                                                  ('categorical_transfo',\n",
       "                                                   Pipeline(steps=[('encoder',\n",
       "                                                                    OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                   <sklearn.compose._column_transformer.make_column_selector object at 0x7f3b7ef58e50>)])),\n",
       "                 ('imb', SMOTEENN(random_state=42)),\n",
       "                 ('clf', RandomForestClassifier(random_state=42))])]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02058c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-20 22:29:36,744]\u001b[0m A new study created in memory with name: test\u001b[0m\n",
      "\u001b[32m[I 2022-09-20 22:29:39,373]\u001b[0m Trial 0 finished with value: 0.9619485208278313 and parameters: {'clf__bosting_type': 'dart', 'clf__num_leaves': 124, 'clf__min_data': 73, 'clf__max_depth': 5, 'clf__reg_alpha': 0.05808361216819946, 'clf__reg_lambda': 0.8661761457749352, 'clf__learning_rate': 0.19956529392808392, 'drop_rate': 0.004619347374377372, 'skip_drop': 1.4610865886287176e-08}. Best is trial 0 with value: 0.9619485208278313.\u001b[0m\n",
      "\u001b[32m[I 2022-09-20 22:29:39,571]\u001b[0m Trial 1 finished with value: 0.9619485208278313 and parameters: {'clf__bosting_type': 'gbdt', 'clf__num_leaves': 44, 'clf__min_data': 77, 'clf__max_depth': 6, 'clf__reg_alpha': 0.5247564316322378, 'clf__reg_lambda': 0.43194501864211576, 'clf__learning_rate': 0.09776854331372624}. Best is trial 0 with value: 0.9619485208278313.\u001b[0m\n",
      "\u001b[32m[I 2022-09-20 22:29:39,583]\u001b[0m A new study created in memory with name: test\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained models saved in ./models/ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-20 22:29:40,197]\u001b[0m Trial 0 finished with value: 0.9434793996425593 and parameters: {'n_estimators': 250, 'max_features': 'auto', 'max_depth': 32, 'min_samples_split': 3, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 0 with value: 0.9434793996425593.\u001b[0m\n",
      "\u001b[32m[I 2022-09-20 22:29:40,817]\u001b[0m Trial 1 finished with value: 0.9434793996425593 and parameters: {'n_estimators': 341, 'max_features': 'auto', 'max_depth': 49, 'min_samples_split': 9, 'min_samples_leaf': 3, 'bootstrap': False}. Best is trial 0 with value: 0.9434793996425593.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained models saved in ./models/ \n"
     ]
    }
   ],
   "source": [
    "for j in pipe_list:\n",
    "    lambda_objective = lambda trial, j=j: tuning.objective(trial, pipeline=j, X_train=X_train, y_train=y_train, cross_validator=5, groups=None, scoring_metric='f1_macro')\n",
    "    my_pipe, my_study = tuning.tune(n_trials=2, objective_function=lambda_objective\n",
    "                                    ,output_folder='./', study_name='test', random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "786245a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "80dcc331",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-20 19:44:24,018]\u001b[0m A new study created in memory with name: test\u001b[0m\n",
      "\u001b[32m[I 2022-09-20 19:44:53,824]\u001b[0m Trial 0 finished with value: 0.9619485208278313 and parameters: {'clf__bosting_type': 'dart', 'clf__num_leaves': 124, 'clf__min_data': 73, 'clf__max_depth': 5, 'clf__reg_alpha': 0.05808361216819946, 'clf__reg_lambda': 0.8661761457749352, 'clf__learning_rate': 0.19956529392808392, 'drop_rate': 0.004619347374377372, 'skip_drop': 1.4610865886287176e-08}. Best is trial 0 with value: 0.9619485208278313.\u001b[0m\n",
      "\u001b[32m[I 2022-09-20 19:45:41,017]\u001b[0m Trial 1 finished with value: 0.9619485208278313 and parameters: {'clf__bosting_type': 'gbdt', 'clf__num_leaves': 44, 'clf__min_data': 77, 'clf__max_depth': 6, 'clf__reg_alpha': 0.5247564316322378, 'clf__reg_lambda': 0.43194501864211576, 'clf__learning_rate': 0.09776854331372624}. Best is trial 0 with value: 0.9619485208278313.\u001b[0m\n",
      "\u001b[32m[I 2022-09-20 19:45:41,030]\u001b[0m A new study created in memory with name: test\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained models saved in ./models/ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-20 19:45:41,661]\u001b[0m Trial 0 finished with value: 0.9434793996425593 and parameters: {'n_estimators': 250, 'max_features': 'auto', 'max_depth': 32, 'min_samples_split': 3, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 0 with value: 0.9434793996425593.\u001b[0m\n",
      "\u001b[32m[I 2022-09-20 19:45:42,306]\u001b[0m Trial 1 finished with value: 0.9434793996425593 and parameters: {'n_estimators': 341, 'max_features': 'auto', 'max_depth': 49, 'min_samples_split': 9, 'min_samples_leaf': 3, 'bootstrap': False}. Best is trial 0 with value: 0.9434793996425593.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained models saved in ./models/ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/geods37/lib/python3.7/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/root/miniconda3/envs/geods37/lib/python3.7/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/root/miniconda3/envs/geods37/lib/python3.7/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/root/miniconda3/envs/geods37/lib/python3.7/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/root/miniconda3/envs/geods37/lib/python3.7/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[19:34:06] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:34:43] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[19:34:06] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:34:43] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:35:18] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[19:34:07] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:34:28] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:34:43] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[19:34:06] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:34:43] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/geods37/lib/python3.7/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/root/miniconda3/envs/geods37/lib/python3.7/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/root/miniconda3/envs/geods37/lib/python3.7/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/root/miniconda3/envs/geods37/lib/python3.7/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/root/miniconda3/envs/geods37/lib/python3.7/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "for p in pipe_list:\n",
    "    lambda_objective = lambda trial: tuning.objective(trial, pipeline=p, X_train=X_train, y_train=y_train, cross_validator=5, groups=None, scoring_metric='f1_macro')\n",
    "    my_pipe, my_study = tuning.tune(n_trials=2, objective_function=lambda_objective\n",
    "                                    ,output_folder='./', study_name='test', random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "b140afe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "imblearn.pipeline.Pipeline"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dp.catboost_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "1a6e3e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_objective = lambda p: p if p == catboost.core.CatBoostClassifier else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "b4e8e6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'catboost.core.CatBoostClassifier'>\n"
     ]
    }
   ],
   "source": [
    "print(lambda_objective(catboost.core.CatBoostClassifier))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "77fb7a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "Max = lambda a, b : a if(a > b) else b\n",
    " \n",
    "print(Max(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e68c5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba43e1f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "51525f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "trial = 2\n",
    "p = dp.lgbm_pipeline\n",
    "\n",
    "print(lambda_objective(trial, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "cf4ba486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('pre',\n",
       "                 ColumnTransformer(transformers=[('numerical_transfo',\n",
       "                                                  Pipeline(steps=[('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x7f811f4db290>),\n",
       "                                                 ('categorical_transfo',\n",
       "                                                  Pipeline(steps=[('encoder',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x7f8110865410>)])),\n",
       "                ('imb', SMOTEENN(random_state=42)),\n",
       "                ('clf', LGBMClassifier(objective='binary', random_state=42))])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp.lgbm_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "159d4568",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-20 20:24:27,420]\u001b[0m A new study created in memory with name: test\u001b[0m\n",
      "\u001b[33m[W 2022-09-20 20:24:27,421]\u001b[0m Trial 0 failed because of the following error: TypeError(\"'NoneType' object is not callable\")\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/geods37/lib/python3.7/site-packages/optuna/study/_optimize.py\", line 213, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "TypeError: 'NoneType' object is not callable\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13/4099192034.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpipes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     my_pipe, my_study = tuning.tune(n_trials=trials, objective_function=lambda_objective(trials, k)\n\u001b[0;32m----> 6\u001b[0;31m                                  ,output_folder='./', study_name='test', random_state=42)\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/geods37/lib/python3.7/site-packages/GeoDS-1.1.0-py3.7.egg/GeoDS/supervised/tuning.py\u001b[0m in \u001b[0;36mtune\u001b[0;34m(n_trials, objective_function, output_folder, study_name, random_state)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0mobjective_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m         \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_trials\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m         callbacks=[callback])\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0mpipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_attrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"best_pipeline\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/geods37/lib/python3.7/site-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgc_after_trial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m             \u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m         )\n\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/geods37/lib/python3.7/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0mreseed_sampler_rng\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0mtime_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                 \u001b[0mprogress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             )\n\u001b[1;32m     78\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/geods37/lib/python3.7/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/geods37/lib/python3.7/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTrialState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFAIL\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfunc_err\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/geods37/lib/python3.7/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "pipes = [dp.lgbm_pipeline, dp.xgboost_pipeline]\n",
    "trials = 2\n",
    "\n",
    "for k in pipes:\n",
    "    my_pipe, my_study = tuning.tune(n_trials=trials, objective_function=lambda_objective(trials, k)\n",
    "                                 ,output_folder='./', study_name='test', random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "86183a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('pre',\n",
      "                 ColumnTransformer(transformers=[('numerical_transfo',\n",
      "                                                  Pipeline(steps=[('scaler',\n",
      "                                                                   StandardScaler())]),\n",
      "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x7f811f4db290>),\n",
      "                                                 ('categorical_transfo',\n",
      "                                                  Pipeline(steps=[('encoder',\n",
      "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
      "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x7f8110865410>)])),\n",
      "                ('imb', SMOTEENN(random_state=42)),\n",
      "                ('clf', LGBMClassifier(objective='binary', random_state=42))])\n",
      "Pipeline(steps=[('pre',\n",
      "                 ColumnTransformer(transformers=[('numerical_transfo',\n",
      "                                                  Pipeline(steps=[('scaler',\n",
      "                                                                   StandardScaler())]),\n",
      "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x7f811f4db290>),\n",
      "                                                 ('categorical_transfo',\n",
      "                                                  Pipeline(steps=[('encoder',\n",
      "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
      "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x7f8110865410>)])),\n",
      "                ('imb', SMOTEENN(random_state=42)),\n",
      "                ('clf', RandomForestClassifier(random_state=42))])\n"
     ]
    }
   ],
   "source": [
    "p = dp.lgbm_pipeline\n",
    "\n",
    "\n",
    "for p in [dp.lgbm_pipeline, dp.random_forest_pipeline]:\n",
    "    print(p)\n",
    "#if(p in [dp.lgbm_pipeline, dp.random_forest_pipeline]):\n",
    "    \n",
    "#    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "891887c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'python' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13/1576056767.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpython\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'python' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a212b740",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf202e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "b90af46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_objective = lambda trial, p: tuning.objective(trial, \n",
    "                                                  pipeline=dp.catboost_pipeline,\n",
    "                                                  X_train=X_train, \n",
    "                                                  y_train=y_train, \n",
    "                                                  cross_validator=5,\n",
    "                                                  groups=None, \n",
    "                                                  scoring_metric='f1_macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "6a28c7a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'suggest_int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13/3497156539.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlambda_objective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatboost_pipeline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_13/3778067880.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(trial, p)\u001b[0m\n\u001b[1;32m      5\u001b[0m                                                   \u001b[0mcross_validator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                                                   \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                                                   scoring_metric='f1_macro')\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/geods37/lib/python3.7/site-packages/GeoDS-1.1.0-py3.7.egg/GeoDS/supervised/tuning.py\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial, pipeline, X_train, y_train, cross_validator, groups, scoring_metric, tune_on)\u001b[0m\n\u001b[1;32m    201\u001b[0m     \"\"\"\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m     \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSuggestor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clf'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0mpipeline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clf'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/geods37/lib/python3.7/site-packages/GeoDS-1.1.0-py3.7.egg/GeoDS/supervised/tuning.py\u001b[0m in \u001b[0;36mget_params\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mCatBoostClassifier\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m             \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatboost_params_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxgboost_params_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/geods37/lib/python3.7/site-packages/GeoDS-1.1.0-py3.7.egg/GeoDS/supervised/tuning.py\u001b[0m in \u001b[0;36mcatboost_params\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcatboost_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     params = {\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0;34m\"iterations\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"iterations\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m250\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;34m\"depth\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"depth\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.03, 0.5),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'suggest_int'"
     ]
    }
   ],
   "source": [
    "lambda_objective = lambda trial, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "36b85e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_objective = lambda trial, p: p**2 if p == 2 else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "b520e272",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_objective(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "31306e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "4\n",
      "9\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "for x in range(1,5): print(square(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "e647596f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from GeoDS.supervised import tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "dd9eb7db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function GeoDS.supervised.tuning.objective(trial, pipeline, X_train, y_train, cross_validator, groups=None, scoring_metric='f1_macro', tune_on='f1_macro')>"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuning.objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "c19d90ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "lambda_objective = lambda trial, p:tuning.objective(trial, \n",
    "                                                  pipeline=p,\n",
    "                                                  X_train=X_train, \n",
    "                                                  y_train=y_train, \n",
    "                                                  cross_validator=5,\n",
    "                                                  groups=None, \n",
    "                                                  scoring_metric='f1_macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "8f739d43",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13/3574809937.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlambda_objective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatboost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_13/3536706672.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(trial, p)\u001b[0m\n\u001b[1;32m      5\u001b[0m                                                   \u001b[0mcross_validator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                                                   \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                                                   scoring_metric='f1_macro')\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/geods37/lib/python3.7/site-packages/GeoDS-1.1.0-py3.7.egg/GeoDS/supervised/tuning.py\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial, pipeline, X_train, y_train, cross_validator, groups, scoring_metric, tune_on)\u001b[0m\n\u001b[1;32m    201\u001b[0m     \"\"\"\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m     \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSuggestor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clf'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0mpipeline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clf'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'module' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "lambda_objective(5, catboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccf23ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b1f4e45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipes = [dp.lgbm_pipeline, dp.random_forest_pipeline]\n",
    "\n",
    "lambda_objective = [(lambda trial, p=p: tuning.objective(trial, \n",
    "                                                  pipeline=p,\n",
    "                                                  X_train=X_train, \n",
    "                                                  y_train=y_train, \n",
    "                                                  cross_validator=5,\n",
    "                                                  groups=None,\n",
    "                                                  scoring_metric='f1_macro')) for p in pipes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d8d53d45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.<listcomp>.<lambda>(trial, p=Pipeline(steps=[('pre',\n",
       "                 ColumnTransformer(transformers=[('numerical_transfo',\n",
       "                                                  Pipeline(steps=[('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x7fea62983450>),\n",
       "                                                 ('categorical_transfo',\n",
       "                                                  Pipeline(steps=[('encoder',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x7fea629835d0>)])),\n",
       "                ('imb', SMOTEENN(random_state=42)),\n",
       "                ('clf', RandomForestClassifier(random_state=42))]))>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_objective[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "92a3f123",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-20 22:27:30,915]\u001b[0m A new study created in memory with name: test\u001b[0m\n",
      "\u001b[32m[I 2022-09-20 22:27:32,070]\u001b[0m Trial 0 finished with value: 0.9619485208278313 and parameters: {'clf__bosting_type': 'dart', 'clf__num_leaves': 124, 'clf__min_data': 73, 'clf__max_depth': 5, 'clf__reg_alpha': 0.05808361216819946, 'clf__reg_lambda': 0.8661761457749352, 'clf__learning_rate': 0.19956529392808392, 'drop_rate': 0.004619347374377372, 'skip_drop': 1.4610865886287176e-08}. Best is trial 0 with value: 0.9619485208278313.\u001b[0m\n",
      "\u001b[32m[I 2022-09-20 22:27:32,254]\u001b[0m Trial 1 finished with value: 0.9619485208278313 and parameters: {'clf__bosting_type': 'gbdt', 'clf__num_leaves': 44, 'clf__min_data': 77, 'clf__max_depth': 6, 'clf__reg_alpha': 0.5247564316322378, 'clf__reg_lambda': 0.43194501864211576, 'clf__learning_rate': 0.09776854331372624}. Best is trial 0 with value: 0.9619485208278313.\u001b[0m\n",
      "\u001b[32m[I 2022-09-20 22:27:32,438]\u001b[0m Trial 2 finished with value: 0.9619485208278313 and parameters: {'clf__bosting_type': 'gbdt', 'clf__num_leaves': 79, 'clf__min_data': 118, 'clf__max_depth': 11, 'clf__reg_alpha': 0.19967378215835974, 'clf__reg_lambda': 0.5142344384136116, 'clf__learning_rate': 0.19560708142748476}. Best is trial 0 with value: 0.9619485208278313.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained models saved in ./models/ \n"
     ]
    }
   ],
   "source": [
    "my_pipe, my_study = tuning.tune(n_trials=3, \n",
    "                                objective_function=lambda_objective[0], \n",
    "                                output_folder='./', \n",
    "                                study_name='test',\n",
    "                                random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "db0649bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 <function <listcomp>.<lambda> at 0x7fea528b2170>\n",
      "1 <function <listcomp>.<lambda> at 0x7feaa819f3b0>\n"
     ]
    }
   ],
   "source": [
    "for i, objective in enumerate(lambda_objective):\n",
    "    print(i, objective)\n",
    "    lambda_objective[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b6d1f348",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-20 22:13:55,754]\u001b[0m A new study created in memory with name: test\u001b[0m\n",
      "\u001b[32m[I 2022-09-20 22:13:58,284]\u001b[0m Trial 0 finished with value: 0.9619485208278313 and parameters: {'clf__bosting_type': 'dart', 'clf__num_leaves': 124, 'clf__min_data': 73, 'clf__max_depth': 5, 'clf__reg_alpha': 0.05808361216819946, 'clf__reg_lambda': 0.8661761457749352, 'clf__learning_rate': 0.19956529392808392, 'drop_rate': 0.004619347374377372, 'skip_drop': 1.4610865886287176e-08}. Best is trial 0 with value: 0.9619485208278313.\u001b[0m\n",
      "\u001b[32m[I 2022-09-20 22:13:58,467]\u001b[0m Trial 1 finished with value: 0.9619485208278313 and parameters: {'clf__bosting_type': 'gbdt', 'clf__num_leaves': 44, 'clf__min_data': 77, 'clf__max_depth': 6, 'clf__reg_alpha': 0.5247564316322378, 'clf__reg_lambda': 0.43194501864211576, 'clf__learning_rate': 0.09776854331372624}. Best is trial 0 with value: 0.9619485208278313.\u001b[0m\n",
      "\u001b[32m[I 2022-09-20 22:13:58,650]\u001b[0m Trial 2 finished with value: 0.9619485208278313 and parameters: {'clf__bosting_type': 'gbdt', 'clf__num_leaves': 79, 'clf__min_data': 118, 'clf__max_depth': 11, 'clf__reg_alpha': 0.19967378215835974, 'clf__reg_lambda': 0.5142344384136116, 'clf__learning_rate': 0.19560708142748476}. Best is trial 0 with value: 0.9619485208278313.\u001b[0m\n",
      "\u001b[32m[I 2022-09-20 22:13:58,663]\u001b[0m A new study created in memory with name: test\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained models saved in ./models/ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-20 22:13:59,282]\u001b[0m Trial 0 finished with value: 0.9434793996425593 and parameters: {'n_estimators': 250, 'max_features': 'auto', 'max_depth': 32, 'min_samples_split': 3, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 0 with value: 0.9434793996425593.\u001b[0m\n",
      "\u001b[32m[I 2022-09-20 22:13:59,891]\u001b[0m Trial 1 finished with value: 0.9434793996425593 and parameters: {'n_estimators': 341, 'max_features': 'auto', 'max_depth': 49, 'min_samples_split': 9, 'min_samples_leaf': 3, 'bootstrap': False}. Best is trial 0 with value: 0.9434793996425593.\u001b[0m\n",
      "\u001b[32m[I 2022-09-20 22:14:00,508]\u001b[0m Trial 2 finished with value: 0.9434793996425593 and parameters: {'n_estimators': 222, 'max_features': 'auto', 'max_depth': 18, 'min_samples_split': 7, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 0 with value: 0.9434793996425593.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained models saved in ./models/ \n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n"
     ]
    }
   ],
   "source": [
    "for objective in lambda_objective:\n",
    "    my_pipe, my_study = tuning.tune(n_trials=3, \n",
    "                                objective_function=objective, \n",
    "                                output_folder='./', \n",
    "                                study_name='test',\n",
    "                                random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34dccc8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab823316",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5fbf7611",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'suggest_categorical'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_125/1744567062.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m                                                   \u001b[0mcross_validator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                                                   \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                                                   scoring_metric='f1_macro')\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     my_pipe, my_study = tuning.tune(n_trials=3, \n",
      "\u001b[0;32m~/miniconda3/envs/geods37/lib/python3.7/site-packages/GeoDS-1.1.0-py3.7.egg/GeoDS/supervised/tuning.py\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial, pipeline, X_train, y_train, cross_validator, groups, scoring_metric, tune_on)\u001b[0m\n\u001b[1;32m    201\u001b[0m     \"\"\"\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m     \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSuggestor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clf'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0mpipeline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clf'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/geods37/lib/python3.7/site-packages/GeoDS-1.1.0-py3.7.egg/GeoDS/supervised/tuning.py\u001b[0m in \u001b[0;36mget_params\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madaboost_params_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mLGBMClassifier\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m             \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlgbm_params_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexisting_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/geods37/lib/python3.7/site-packages/GeoDS-1.1.0-py3.7.egg/GeoDS/supervised/tuning.py\u001b[0m in \u001b[0;36mlightgbm_params\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlightgbm_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     params = {\"boosting_type\": trial.suggest_categorical(\"clf__bosting_type\", ['gbdt', 'dart', 'goss']),\n\u001b[0m\u001b[1;32m     44\u001b[0m               \u001b[0;34m\"num_leaves\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'clf__num_leaves'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m               \u001b[0;34m\"min_data\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'clf__min_data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'suggest_categorical'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_data=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n"
     ]
    }
   ],
   "source": [
    "pipes = [dp.lgbm_pipeline, dp.random_forest_pipeline]\n",
    "trial = 3\n",
    "\n",
    "\n",
    "for p in pipes:\n",
    "    lambda_objective = tuning.objective(trial, \n",
    "                                        pipeline=p,\n",
    "                                        X_train=X_train, \n",
    "                                        y_train=y_train, \n",
    "                                                  cross_validator=5,\n",
    "                                                  groups=None,\n",
    "                                                  scoring_metric='f1_macro')\n",
    "\n",
    "    my_pipe, my_study = tuning.tune(n_trials=3, \n",
    "                                objective_function=lambda_objective, \n",
    "                                output_folder='./', \n",
    "                                study_name='test',\n",
    "                                random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772b4f90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab8f5cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d4d05992",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipes = [dp.lgbm_pipeline, dp.random_forest_pipeline]\n",
    "\n",
    "lambda_objective = [(lambda trial, p=p: tuning.objective(trial, \n",
    "                                                  pipeline=p,\n",
    "                                                  X_train=X_train, \n",
    "                                                  y_train=y_train, \n",
    "                                                  cross_validator=5,\n",
    "                                                  groups=None,\n",
    "                                                  scoring_metric='f1_macro')) for p in pipes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "376a481b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.<listcomp>.<lambda>(trial, p=Pipeline(steps=[('pre',\n",
       "                 ColumnTransformer(transformers=[('numerical_transfo',\n",
       "                                                  Pipeline(steps=[('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x7f639740b3d0>),\n",
       "                                                 ('categorical_transfo',\n",
       "                                                  Pipeline(steps=[('encoder',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x7f639740b110>)])),\n",
       "                ('imb', SMOTEENN(random_state=42)),\n",
       "                ('clf', LGBMClassifier(objective='binary', random_state=42))]))>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_objective[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3feb19ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "37c5b30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_objective = lambda trial, p=p: tuning.objective(trial, \n",
    "                                                  pipeline=p,\n",
    "                                                  X_train=X_train, \n",
    "                                                  y_train=y_train, \n",
    "                                                  cross_validator=5,\n",
    "                                                  groups=None,\n",
    "                                                  scoring_metric='f1_macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6f28fb44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<function __main__.<lambda>(trial, p=Pipeline(steps=[('pre',\n",
       "                 ColumnTransformer(transformers=[('numerical_transfo',\n",
       "                                                  Pipeline(steps=[('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x7f639cc40410>),\n",
       "                                                 ('categorical_transfo',\n",
       "                                                  Pipeline(steps=[('encoder',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x7f63af4d5050>)])),\n",
       "                ('imb', SMOTEENN(random_state=42)),\n",
       "                ('clf', LGBMClassifier(objective='binary', random_state=42))]))>,\n",
       " <function __main__.<lambda>(trial, p=Pipeline(steps=[('pre',\n",
       "                 ColumnTransformer(transformers=[('numerical_transfo',\n",
       "                                                  Pipeline(steps=[('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x7f639cc40410>),\n",
       "                                                 ('categorical_transfo',\n",
       "                                                  Pipeline(steps=[('encoder',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x7f63af4d5050>)])),\n",
       "                ('imb', SMOTEENN(random_state=42)),\n",
       "                ('clf', LGBMClassifier(objective='binary', random_state=42))]))>]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipes = [dp.lgbm_pipeline, dp.random_forest_pipeline]\n",
    "trial = 5\n",
    "\n",
    "[lambda_objective for p in pipes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f475ec04",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_pipe, my_study = tuning.tune(n_trials=5, \n",
    "                                objective_function=lambda_objective, \n",
    "                                output_folder='./', \n",
    "                                study_name='test', \n",
    "                                random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35ca44f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ffd4913f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_objective = map(lambda trial: tuning.objective(trial, \n",
    "                                                  pipeline=dp.lgbm_pipeline,\n",
    "                                                  X_train=X_train, \n",
    "                                                  y_train=y_train, \n",
    "                                                  cross_validator=5,\n",
    "                                                  groups=None,\n",
    "                                                  scoring_metric='f1_macro'), pipes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f0396a49",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Pipeline' object has no attribute 'suggest_categorical'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_125/154505953.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlambda_objective\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_125/1346779310.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m      5\u001b[0m                                                   \u001b[0mcross_validator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                                                   \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                                                   scoring_metric='f1_macro'), pipes)\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/geods37/lib/python3.7/site-packages/GeoDS-1.1.0-py3.7.egg/GeoDS/supervised/tuning.py\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial, pipeline, X_train, y_train, cross_validator, groups, scoring_metric, tune_on)\u001b[0m\n\u001b[1;32m    201\u001b[0m     \"\"\"\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m     \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSuggestor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clf'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0mpipeline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clf'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/geods37/lib/python3.7/site-packages/GeoDS-1.1.0-py3.7.egg/GeoDS/supervised/tuning.py\u001b[0m in \u001b[0;36mget_params\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madaboost_params_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mLGBMClassifier\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m             \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlgbm_params_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexisting_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/geods37/lib/python3.7/site-packages/GeoDS-1.1.0-py3.7.egg/GeoDS/supervised/tuning.py\u001b[0m in \u001b[0;36mlightgbm_params\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlightgbm_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     params = {\"boosting_type\": trial.suggest_categorical(\"clf__bosting_type\", ['gbdt', 'dart', 'goss']),\n\u001b[0m\u001b[1;32m     44\u001b[0m               \u001b[0;34m\"num_leaves\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'clf__num_leaves'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m               \u001b[0;34m\"min_data\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'clf__min_data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Pipeline' object has no attribute 'suggest_categorical'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(list(lambda_objective))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c220f89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29d90df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ee8d5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19156e97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9e38cf4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-20 22:42:26,583]\u001b[0m A new study created in memory with name: test\u001b[0m\n",
      "\u001b[32m[I 2022-09-20 22:42:26,768]\u001b[0m Trial 0 finished with value: 0.9619485208278313 and parameters: {'clf__bosting_type': 'dart', 'clf__num_leaves': 124, 'clf__min_data': 73, 'clf__max_depth': 5, 'clf__reg_alpha': 0.05808361216819946, 'clf__reg_lambda': 0.8661761457749352, 'clf__learning_rate': 0.19956529392808392, 'drop_rate': 0.004619347374377372, 'skip_drop': 1.4610865886287176e-08}. Best is trial 0 with value: 0.9619485208278313.\u001b[0m\n",
      "\u001b[32m[I 2022-09-20 22:42:26,953]\u001b[0m Trial 1 finished with value: 0.9619485208278313 and parameters: {'clf__bosting_type': 'gbdt', 'clf__num_leaves': 44, 'clf__min_data': 77, 'clf__max_depth': 6, 'clf__reg_alpha': 0.5247564316322378, 'clf__reg_lambda': 0.43194501864211576, 'clf__learning_rate': 0.09776854331372624}. Best is trial 0 with value: 0.9619485208278313.\u001b[0m\n",
      "\u001b[32m[I 2022-09-20 22:42:27,144]\u001b[0m Trial 2 finished with value: 0.9619485208278313 and parameters: {'clf__bosting_type': 'gbdt', 'clf__num_leaves': 79, 'clf__min_data': 118, 'clf__max_depth': 11, 'clf__reg_alpha': 0.19967378215835974, 'clf__reg_lambda': 0.5142344384136116, 'clf__learning_rate': 0.19560708142748476}. Best is trial 0 with value: 0.9619485208278313.\u001b[0m\n",
      "\u001b[32m[I 2022-09-20 22:42:27,157]\u001b[0m A new study created in memory with name: test\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained models saved in ./models/ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-20 22:42:27,772]\u001b[0m Trial 0 finished with value: 0.9434793996425593 and parameters: {'n_estimators': 250, 'max_features': 'auto', 'max_depth': 32, 'min_samples_split': 3, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 0 with value: 0.9434793996425593.\u001b[0m\n",
      "\u001b[32m[I 2022-09-20 22:42:28,387]\u001b[0m Trial 1 finished with value: 0.9434793996425593 and parameters: {'n_estimators': 341, 'max_features': 'auto', 'max_depth': 49, 'min_samples_split': 9, 'min_samples_leaf': 3, 'bootstrap': False}. Best is trial 0 with value: 0.9434793996425593.\u001b[0m\n",
      "\u001b[32m[I 2022-09-20 22:42:29,004]\u001b[0m Trial 2 finished with value: 0.9434793996425593 and parameters: {'n_estimators': 222, 'max_features': 'auto', 'max_depth': 18, 'min_samples_split': 7, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 0 with value: 0.9434793996425593.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained models saved in ./models/ \n"
     ]
    }
   ],
   "source": [
    "for i in range(len(lambda_objective)):\n",
    "    my_pipe, my_study = tuning.tune(n_trials=3, \n",
    "                                objective_function=lambda_objective[i], \n",
    "                                output_folder='./', \n",
    "                                study_name='test',\n",
    "                                random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bed749",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05df2c89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d139767b",
   "metadata": {},
   "outputs": [],
   "source": [
    "aaa = lambda trial, p=p: tuning.objective(trial, \n",
    "                                    pipeline=dp.lgbm_pipeline,\n",
    "                                                  X_train=X_train, \n",
    "                                                  y_train=y_train, \n",
    "                                                  cross_validator=5,\n",
    "                                                  groups=None,\n",
    "                                                  scoring_metric='f1_macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "23ad81a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.<lambda>(trial, p=Pipeline(steps=[('pre',\n",
       "                 ColumnTransformer(transformers=[('numerical_transfo',\n",
       "                                                  Pipeline(steps=[('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x7f639cc40410>),\n",
       "                                                 ('categorical_transfo',\n",
       "                                                  Pipeline(steps=[('encoder',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x7f63af4d5050>)])),\n",
       "                ('imb', SMOTEENN(random_state=42)),\n",
       "                ('clf', LGBMClassifier(objective='binary', random_state=42))]))>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb94069",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ee104b26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = lambda x: x*x\n",
    "[f(x) for x in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cc93a235",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<function __main__.<listcomp>.<lambda>(x)>,\n",
       " <function __main__.<listcomp>.<lambda>(x)>,\n",
       " <function __main__.<listcomp>.<lambda>(x)>,\n",
       " <function __main__.<listcomp>.<lambda>(x)>,\n",
       " <function __main__.<listcomp>.<lambda>(x)>,\n",
       " <function __main__.<listcomp>.<lambda>(x)>,\n",
       " <function __main__.<listcomp>.<lambda>(x)>,\n",
       " <function __main__.<listcomp>.<lambda>(x)>,\n",
       " <function __main__.<listcomp>.<lambda>(x)>,\n",
       " <function __main__.<listcomp>.<lambda>(x)>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[lambda x: x*x for x in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "59e95bcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('pre',\n",
       "                 ColumnTransformer(transformers=[('numerical_transfo',\n",
       "                                                  Pipeline(steps=[('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x7f639740b3d0>),\n",
       "                                                 ('categorical_transfo',\n",
       "                                                  Pipeline(steps=[('encoder',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x7f639740b110>)])),\n",
       "                ('imb', SMOTEENN(random_state=42)),\n",
       "                ('clf', LGBMClassifier(objective='binary', random_state=42))])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp.lgbm_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996e2e3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Geods Kernel",
   "language": "python",
   "name": "geods"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
